{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-11T03:46:31.667989Z",
     "start_time": "2024-08-11T03:46:31.640232Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# download ffmpeg (https://www.ffmpeg.org/download.html) and set the path\n",
    "ffmpeg_path = r\"C:\\Users\\Sudheera\\Documents\\ffmpeg-n6.1-latest-win64-gpl-6.1\\ffmpeg-n6.1-latest-win64-gpl-6.1\\bin\"\n",
    "os.environ['PATH'] += os.pathsep + ffmpeg_path\n",
    "\n",
    "with open('vars.json') as f:\n",
    "    data = json.load(f)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Download subtitles from YouTube",
   "id": "948dc3f6289df5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T03:46:35.271766Z",
     "start_time": "2024-08-11T03:46:34.106494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yt_dlp\n",
    "\n",
    "\n",
    "# Function to download subtitles\n",
    "def download_subtitles(url, lang='en'):\n",
    "    ydl_opts = {\n",
    "        'writesubtitles': True,  # Download subtitles\n",
    "        'writeautomaticsub': True,  # Download automatic subtitles generated by YouTube\n",
    "        'subtitleslangs': [lang],  # Subtitle language (default is English)\n",
    "        'subtitlesformat': 'srt',  # Format for subtitles (e.g., srt, vtt)\n",
    "        'skip_download': True,  # Do not download the video file itself\n",
    "        'restrictfilenames': True,  # Do not allow special characters in file names\n",
    "        'outtmpl': '%(title)s.%(ext)s',  # Output file naming\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])"
   ],
   "id": "159f99bccafc0d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T03:46:50.249025Z",
     "start_time": "2024-08-11T03:46:38.245591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# URL of the YouTube video\n",
    "video_url = 'https://www.youtube.com/watch?v=CDZ9REOh2xA'\n",
    "\n",
    "# Download subtitle\n",
    "download_subtitles(video_url)"
   ],
   "id": "39e9f14ec6e3cce7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=CDZ9REOh2xA\n",
      "[youtube] CDZ9REOh2xA: Downloading webpage\n",
      "[youtube] CDZ9REOh2xA: Downloading ios player API JSON\n",
      "[youtube] CDZ9REOh2xA: Downloading web creator player API JSON\n",
      "[youtube] CDZ9REOh2xA: Downloading m3u8 information\n",
      "[info] CDZ9REOh2xA: Downloading subtitles: en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: No subtitle format found matching \"srt\" for language en, using vtt. Use --list-subs for a list of available subtitles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] CDZ9REOh2xA: Downloading 1 format(s): 616+251\n",
      "[info] Writing video subtitles to: Elon_Musk_s_approach_to_problem-solving_Lex_Fridman_Podcast.en.vtt\n",
      "[download] Destination: Elon_Musk_s_approach_to_problem-solving_Lex_Fridman_Podcast.en.vtt\n",
      "[download] 100% of   68.77KiB in 00:00:00 at 76.26KiB/s\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Download audio file from Youtube and transcribe it using Google Speech to Text",
   "id": "26a1fea838f2bee7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T03:49:05.486432Z",
     "start_time": "2024-08-11T03:49:05.473708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yt_dlp\n",
    "\n",
    "\n",
    "def download_audio(youtube_url, output_file):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',  # Select the best available audio quality\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3'  # You can change this to 'wav', 'm4a', etc.\n",
    "        }],\n",
    "        'outtmpl': output_file,  # Output file name and path\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([youtube_url])\n",
    "\n",
    "    return True"
   ],
   "id": "85515c2ad2da6ca",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T03:50:42.245843Z",
     "start_time": "2024-08-11T03:50:11.417461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download Audio\n",
    "download_audio(video_url, 'audio_new')"
   ],
   "id": "8c255b977665f15e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=CDZ9REOh2xA\n",
      "[youtube] CDZ9REOh2xA: Downloading webpage\n",
      "[youtube] CDZ9REOh2xA: Downloading ios player API JSON\n",
      "[youtube] CDZ9REOh2xA: Downloading web creator player API JSON\n",
      "[youtube] CDZ9REOh2xA: Downloading m3u8 information\n",
      "[info] CDZ9REOh2xA: Downloading 1 format(s): 251\n",
      "[download] Destination: audio_new\n",
      "[download] 100% of    6.53MiB in 00:00:07 at 928.98KiB/s \n",
      "[ExtractAudio] Destination: audio_new.mp3\n",
      "Deleting original file audio_new (pass -k to keep)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T03:50:51.786709Z",
     "start_time": "2024-08-11T03:50:49.736149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "audio_file_path = r\"audio_new.mp3\"\n",
    "\n",
    "import io\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Read the audio file into memory using io.BytesIO\n",
    "with open(audio_file_path, 'rb') as audio_file:\n",
    "    audio_data = io.BytesIO(audio_file.read())\n",
    "\n",
    "    # Load the audio from the in-memory file\n",
    "    audio = AudioSegment.from_file(audio_data, format=\"mp3\")\n",
    "\n",
    "    # Print the sampling rate\n",
    "    print(f\"Sampling Rate: {audio.frame_rate} Hz\")"
   ],
   "id": "b38922ae5e56f7f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Rate: 48000 Hz\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Transcribe the audio using Google Speech to Text",
   "id": "7a7fc1baff0b1d07"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ee2a796579bec41f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Pre-process downloaded transcript",
   "id": "3d034672ae2e960d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T07:30:33.940570Z",
     "start_time": "2024-08-17T07:30:33.025877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# After transcribing an audio file you can download a csv file and a Json file from Google Speech-to-text\n",
    "# csv :- transcript, confidence, speaker tag, language code, start time, end time (some words can be wrong)\n",
    "# json :- Additional information you have here is the confidence of each word\n",
    "\n",
    "# first we will read files separately and create one dataframe with necessary data \n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "csv_file = 'audio.csv'\n",
    "json_file = 'audio.json'\n",
    "\n",
    "csv_column_names = {\n",
    "    'Start time': 'start_time',\n",
    "    'End time': 'end_time',\n",
    "    'Language code': 'language_code',\n",
    "    'Confidence': 'confidence',\n",
    "    'Channel': 'channel',\n",
    "    'Speaker tag': 'speaker_tag',\n",
    "    'Transcript': 'transcript'\n",
    "}\n",
    "\n",
    "# Json file format :- \n",
    "# {\n",
    "#    \"results\": [\n",
    "#        { \"alternatives\": [\n",
    "#               {\n",
    "#                   \"confidence\": _\n",
    "#                   \"transcript\": _\n",
    "#                   \"words\": [\n",
    "#                       {\n",
    "#                           \"confidence\": _,\n",
    "#                           \"endTime\": _,\n",
    "#                           \"startTime\": _,\n",
    "#                           \"word\": _\n",
    "#                       }, ...\n",
    "#           ],\n",
    "#           \"languageCode\": _,\n",
    "#           \"resultEndTime\": _\n",
    "#       }, ...\n",
    "#       ...\n",
    "#       ...\n",
    "#       {                                           <- last item of the list (after all transcriptions)\n",
    "#           \"alternatives\": {\n",
    "#               \"words\": [\n",
    "#                   {\n",
    "#                      \"confidence\": _,\n",
    "#                      \"endTime\": _,\n",
    "#                      \"speakerLabel\": _,\n",
    "#                      \"speakerTag\": _,\n",
    "#                      \"startTime\": _,\n",
    "#                      \"word\": _\n",
    "#                   },....                          <- one item for each word\n",
    "#               ]\n",
    "#           }\n",
    "#       }\n",
    "#   ]\n",
    "# }"
   ],
   "id": "ce32b5256bfb3727",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T07:30:33.987143Z",
     "start_time": "2024-08-17T07:30:33.946571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read the csv file\n",
    "import hashlib\n",
    "\n",
    "\n",
    "def get_sha256_hash(input_string):\n",
    "    encoded_string = input_string.encode()\n",
    "    sha256_hash = hashlib.sha256(encoded_string)\n",
    "    return sha256_hash.hexdigest()\n",
    "\n",
    "\n",
    "transcript_df = pd.read_csv(csv_file)\n",
    "transcript_df.rename(columns=csv_column_names, inplace=True)\n",
    "transcript_df.drop(columns=['channel'], inplace=True)\n",
    "transcript_df['hashed_transcript'] = transcript_df['transcript'].apply(get_sha256_hash)\n",
    "transcript_df"
   ],
   "id": "2773ab63bde965db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    start_time  end_time language_code  confidence  speaker_tag  \\\n",
       "0          2.8      14.5         en-us     0.96046            1   \n",
       "1         15.4      18.1         en-us     0.84458            1   \n",
       "2         22.9      29.3         en-us     0.82285            2   \n",
       "3         32.7      41.8         en-us     0.88606            2   \n",
       "4         44.3      48.9         en-us     0.72278            2   \n",
       "..         ...       ...           ...         ...          ...   \n",
       "86       489.4     497.2         en-us     0.83681            2   \n",
       "87       497.2     502.1         en-us     0.83681            1   \n",
       "88       502.8     503.1         en-us     0.53844            1   \n",
       "89       504.1     505.5         en-us     0.90823            1   \n",
       "90       506.7     507.8         en-us     0.70052            1   \n",
       "\n",
       "                                           transcript  \\\n",
       "0   Can you just speak to what it takes for great ...   \n",
       "1    process of the process of constantly improvin...   \n",
       "2    Well, these are to say simplify as vertical t...   \n",
       "3    You know how this very basic first basic firs...   \n",
       "4    The requirements always down to some degree. ...   \n",
       "..                                                ...   \n",
       "86   look at the gray matter, which is the compute...   \n",
       "87   like walking around in the super computer cen...   \n",
       "88                                        Yeah, well.   \n",
       "89                  one day build a super intelligent   \n",
       "90                So super super intelligence system.   \n",
       "\n",
       "                                    hashed_transcript  \n",
       "0   a5350f3f9dfe18a3401a06f9972b31bab70158e3bed551...  \n",
       "1   7765622ac3bfe9d45ebd6d1418c06e5f34fe2726ad6190...  \n",
       "2   f244266073005f037d09105a548175753ed8d105419285...  \n",
       "3   6cdc50f14fc9676f34f8dcb7ce5fec772d6e77a844236e...  \n",
       "4   ac34c4be5f95eb462a15976a7445f3c91c2dd8b24e586f...  \n",
       "..                                                ...  \n",
       "86  3c0ab2fae4413f984ce660e62cc68cd594907607e88449...  \n",
       "87  20078ff5635fc66c05669d581f7e12cdce2e95dbabe8de...  \n",
       "88  63ba1f77d332ea3b44f03b603d5061b69e9b8a599c1278...  \n",
       "89  66f6b248588f96d27582131f394fde8035d9d5916b3571...  \n",
       "90  3aba776bd932b4f07c4d785d5a0e66513b84b505df8e34...  \n",
       "\n",
       "[91 rows x 7 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>language_code</th>\n",
       "      <th>confidence</th>\n",
       "      <th>speaker_tag</th>\n",
       "      <th>transcript</th>\n",
       "      <th>hashed_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.8</td>\n",
       "      <td>14.5</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.96046</td>\n",
       "      <td>1</td>\n",
       "      <td>Can you just speak to what it takes for great ...</td>\n",
       "      <td>a5350f3f9dfe18a3401a06f9972b31bab70158e3bed551...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.4</td>\n",
       "      <td>18.1</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.84458</td>\n",
       "      <td>1</td>\n",
       "      <td>process of the process of constantly improvin...</td>\n",
       "      <td>7765622ac3bfe9d45ebd6d1418c06e5f34fe2726ad6190...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.9</td>\n",
       "      <td>29.3</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.82285</td>\n",
       "      <td>2</td>\n",
       "      <td>Well, these are to say simplify as vertical t...</td>\n",
       "      <td>f244266073005f037d09105a548175753ed8d105419285...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.7</td>\n",
       "      <td>41.8</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.88606</td>\n",
       "      <td>2</td>\n",
       "      <td>You know how this very basic first basic firs...</td>\n",
       "      <td>6cdc50f14fc9676f34f8dcb7ce5fec772d6e77a844236e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.3</td>\n",
       "      <td>48.9</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.72278</td>\n",
       "      <td>2</td>\n",
       "      <td>The requirements always down to some degree. ...</td>\n",
       "      <td>ac34c4be5f95eb462a15976a7445f3c91c2dd8b24e586f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>489.4</td>\n",
       "      <td>497.2</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.83681</td>\n",
       "      <td>2</td>\n",
       "      <td>look at the gray matter, which is the compute...</td>\n",
       "      <td>3c0ab2fae4413f984ce660e62cc68cd594907607e88449...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>497.2</td>\n",
       "      <td>502.1</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.83681</td>\n",
       "      <td>1</td>\n",
       "      <td>like walking around in the super computer cen...</td>\n",
       "      <td>20078ff5635fc66c05669d581f7e12cdce2e95dbabe8de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>502.8</td>\n",
       "      <td>503.1</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.53844</td>\n",
       "      <td>1</td>\n",
       "      <td>Yeah, well.</td>\n",
       "      <td>63ba1f77d332ea3b44f03b603d5061b69e9b8a599c1278...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>504.1</td>\n",
       "      <td>505.5</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.90823</td>\n",
       "      <td>1</td>\n",
       "      <td>one day build a super intelligent</td>\n",
       "      <td>66f6b248588f96d27582131f394fde8035d9d5916b3571...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>506.7</td>\n",
       "      <td>507.8</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.70052</td>\n",
       "      <td>1</td>\n",
       "      <td>So super super intelligence system.</td>\n",
       "      <td>3aba776bd932b4f07c4d785d5a0e66513b84b505df8e34...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T07:30:34.079198Z",
     "start_time": "2024-08-17T07:30:34.061202Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"number of transcripts :- {transcript_df.shape[0]}\")",
   "id": "222ca01e65e01b4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of transcripts :- 91\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T07:30:34.697570Z",
     "start_time": "2024-08-17T07:30:34.664916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data from JSON file\n",
    "with open(json_file, 'r') as f:\n",
    "    transcript_json = json.load(f)\n",
    "\n",
    "print(len(transcript_json['results']))"
   ],
   "id": "b1488069d6574c00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T07:30:35.142018Z",
     "start_time": "2024-08-17T07:30:35.083209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transcript_json_df_cols = ['transcript', 'less_confident_words']\n",
    "\n",
    "# less_confident_words = [{\n",
    "#    \"word\": _,\n",
    "#    \"confidence\": _\n",
    "#    \"index_in_transcript\": _\n",
    "#    }, ...]\n",
    "\n",
    "transcript_json_df = pd.DataFrame(columns=transcript_json_df_cols)\n",
    "\n",
    "\n",
    "def _get_less_confident_words_(words):\n",
    "    less_confident_words = []\n",
    "    for idx, word in enumerate(words):\n",
    "        if word['confidence'] < 0.8:\n",
    "            less_confident_words.append({\n",
    "                'word': word['word'],\n",
    "                'index_in_transcript': idx\n",
    "            })\n",
    "    return less_confident_words\n",
    "\n",
    "\n",
    "for itm in transcript_json['results'][:-1]:\n",
    "    transcript_json_row_data = {'transcript': [itm['alternatives'][0]['transcript']],\n",
    "                                'less_confident_words': str(_get_less_confident_words_(itm['alternatives'][0]['words']))\n",
    "                                }\n",
    "    transcript_json_df = pd.concat([transcript_json_df, pd.DataFrame.from_dict(transcript_json_row_data)],\n",
    "                                   ignore_index=True)\n",
    "\n",
    "transcript_json_df['hashed_transcript'] = transcript_json_df['transcript'].apply(get_sha256_hash)\n",
    "transcript_json_df"
   ],
   "id": "3df57a849ca18c7f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                           transcript  \\\n",
       "0   Can you just speak to what it takes for great ...   \n",
       "1    process of the process of constantly improvin...   \n",
       "2    Well, these are to say simplify as vertical t...   \n",
       "3    You know how this very basic first basic firs...   \n",
       "4    The requirements always down to some degree. ...   \n",
       "..                                                ...   \n",
       "70   It looks pretty cool. Yeah, it's like it's li...   \n",
       "71   brain tissue is the cables. Yeah. So look at ...   \n",
       "72                                        Yeah, well.   \n",
       "73                  one day build a super intelligent   \n",
       "74                So super super intelligence system.   \n",
       "\n",
       "                                 less_confident_words  \\\n",
       "0   [{'word': 'the', 'index_in_transcript': 19}, {...   \n",
       "1   [{'word': 'of', 'index_in_transcript': 1}, {'w...   \n",
       "2   [{'word': 'these', 'index_in_transcript': 1}, ...   \n",
       "3   [{'word': 'how', 'index_in_transcript': 2}, {'...   \n",
       "4   [{'word': 'The', 'index_in_transcript': 0}, {'...   \n",
       "..                                                ...   \n",
       "70  [{'word': 'the', 'index_in_transcript': 9}, {'...   \n",
       "71  [{'word': 'brain', 'index_in_transcript': 0}, ...   \n",
       "72  [{'word': 'Yeah,', 'index_in_transcript': 0}, ...   \n",
       "73                                                 []   \n",
       "74  [{'word': 'So', 'index_in_transcript': 0}, {'w...   \n",
       "\n",
       "                                    hashed_transcript  \n",
       "0   a5350f3f9dfe18a3401a06f9972b31bab70158e3bed551...  \n",
       "1   7765622ac3bfe9d45ebd6d1418c06e5f34fe2726ad6190...  \n",
       "2   f244266073005f037d09105a548175753ed8d105419285...  \n",
       "3   6cdc50f14fc9676f34f8dcb7ce5fec772d6e77a844236e...  \n",
       "4   ac34c4be5f95eb462a15976a7445f3c91c2dd8b24e586f...  \n",
       "..                                                ...  \n",
       "70  ee14698c0a54d64462b3858ada257156ecc0139bd16ea8...  \n",
       "71  156fcdf6552db47fc22afdeb8b752420a1c3407f53aa55...  \n",
       "72  63ba1f77d332ea3b44f03b603d5061b69e9b8a599c1278...  \n",
       "73  66f6b248588f96d27582131f394fde8035d9d5916b3571...  \n",
       "74  3aba776bd932b4f07c4d785d5a0e66513b84b505df8e34...  \n",
       "\n",
       "[75 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>less_confident_words</th>\n",
       "      <th>hashed_transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can you just speak to what it takes for great ...</td>\n",
       "      <td>[{'word': 'the', 'index_in_transcript': 19}, {...</td>\n",
       "      <td>a5350f3f9dfe18a3401a06f9972b31bab70158e3bed551...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>process of the process of constantly improvin...</td>\n",
       "      <td>[{'word': 'of', 'index_in_transcript': 1}, {'w...</td>\n",
       "      <td>7765622ac3bfe9d45ebd6d1418c06e5f34fe2726ad6190...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, these are to say simplify as vertical t...</td>\n",
       "      <td>[{'word': 'these', 'index_in_transcript': 1}, ...</td>\n",
       "      <td>f244266073005f037d09105a548175753ed8d105419285...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You know how this very basic first basic firs...</td>\n",
       "      <td>[{'word': 'how', 'index_in_transcript': 2}, {'...</td>\n",
       "      <td>6cdc50f14fc9676f34f8dcb7ce5fec772d6e77a844236e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The requirements always down to some degree. ...</td>\n",
       "      <td>[{'word': 'The', 'index_in_transcript': 0}, {'...</td>\n",
       "      <td>ac34c4be5f95eb462a15976a7445f3c91c2dd8b24e586f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>It looks pretty cool. Yeah, it's like it's li...</td>\n",
       "      <td>[{'word': 'the', 'index_in_transcript': 9}, {'...</td>\n",
       "      <td>ee14698c0a54d64462b3858ada257156ecc0139bd16ea8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>brain tissue is the cables. Yeah. So look at ...</td>\n",
       "      <td>[{'word': 'brain', 'index_in_transcript': 0}, ...</td>\n",
       "      <td>156fcdf6552db47fc22afdeb8b752420a1c3407f53aa55...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Yeah, well.</td>\n",
       "      <td>[{'word': 'Yeah,', 'index_in_transcript': 0}, ...</td>\n",
       "      <td>63ba1f77d332ea3b44f03b603d5061b69e9b8a599c1278...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>one day build a super intelligent</td>\n",
       "      <td>[]</td>\n",
       "      <td>66f6b248588f96d27582131f394fde8035d9d5916b3571...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>So super super intelligence system.</td>\n",
       "      <td>[{'word': 'So', 'index_in_transcript': 0}, {'w...</td>\n",
       "      <td>3aba776bd932b4f07c4d785d5a0e66513b84b505df8e34...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T07:30:35.799004Z",
     "start_time": "2024-08-17T07:30:35.754383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# merge two dataframes \n",
    "transcript_merged_df = pd.merge(transcript_df, transcript_json_df, on='hashed_transcript', how='left',\n",
    "                                suffixes=('_csv', '_json'))\n",
    "transcript_merged_df.sort_values(by='start_time', inplace=True)\n",
    "transcript_merged_df"
   ],
   "id": "68ecae2f824a3101",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    start_time  end_time language_code  confidence  speaker_tag  \\\n",
       "0          2.8      14.5         en-us     0.96046            1   \n",
       "1         15.4      18.1         en-us     0.84458            1   \n",
       "2         22.9      29.3         en-us     0.82285            2   \n",
       "3         32.7      41.8         en-us     0.88606            2   \n",
       "4         44.3      48.9         en-us     0.72278            2   \n",
       "..         ...       ...           ...         ...          ...   \n",
       "88       489.4     497.2         en-us     0.83681            2   \n",
       "89       497.2     502.1         en-us     0.83681            1   \n",
       "90       502.8     503.1         en-us     0.53844            1   \n",
       "91       504.1     505.5         en-us     0.90823            1   \n",
       "92       506.7     507.8         en-us     0.70052            1   \n",
       "\n",
       "                                       transcript_csv  \\\n",
       "0   Can you just speak to what it takes for great ...   \n",
       "1    process of the process of constantly improvin...   \n",
       "2    Well, these are to say simplify as vertical t...   \n",
       "3    You know how this very basic first basic firs...   \n",
       "4    The requirements always down to some degree. ...   \n",
       "..                                                ...   \n",
       "88   look at the gray matter, which is the compute...   \n",
       "89   like walking around in the super computer cen...   \n",
       "90                                        Yeah, well.   \n",
       "91                  one day build a super intelligent   \n",
       "92                So super super intelligence system.   \n",
       "\n",
       "                                    hashed_transcript  \\\n",
       "0   a5350f3f9dfe18a3401a06f9972b31bab70158e3bed551...   \n",
       "1   7765622ac3bfe9d45ebd6d1418c06e5f34fe2726ad6190...   \n",
       "2   f244266073005f037d09105a548175753ed8d105419285...   \n",
       "3   6cdc50f14fc9676f34f8dcb7ce5fec772d6e77a844236e...   \n",
       "4   ac34c4be5f95eb462a15976a7445f3c91c2dd8b24e586f...   \n",
       "..                                                ...   \n",
       "88  3c0ab2fae4413f984ce660e62cc68cd594907607e88449...   \n",
       "89  20078ff5635fc66c05669d581f7e12cdce2e95dbabe8de...   \n",
       "90  63ba1f77d332ea3b44f03b603d5061b69e9b8a599c1278...   \n",
       "91  66f6b248588f96d27582131f394fde8035d9d5916b3571...   \n",
       "92  3aba776bd932b4f07c4d785d5a0e66513b84b505df8e34...   \n",
       "\n",
       "                                      transcript_json  \\\n",
       "0   Can you just speak to what it takes for great ...   \n",
       "1    process of the process of constantly improvin...   \n",
       "2    Well, these are to say simplify as vertical t...   \n",
       "3    You know how this very basic first basic firs...   \n",
       "4    The requirements always down to some degree. ...   \n",
       "..                                                ...   \n",
       "88                                                NaN   \n",
       "89                                                NaN   \n",
       "90                                        Yeah, well.   \n",
       "91                  one day build a super intelligent   \n",
       "92                So super super intelligence system.   \n",
       "\n",
       "                                 less_confident_words  \n",
       "0   [{'word': 'the', 'index_in_transcript': 19}, {...  \n",
       "1   [{'word': 'of', 'index_in_transcript': 1}, {'w...  \n",
       "2   [{'word': 'these', 'index_in_transcript': 1}, ...  \n",
       "3   [{'word': 'how', 'index_in_transcript': 2}, {'...  \n",
       "4   [{'word': 'The', 'index_in_transcript': 0}, {'...  \n",
       "..                                                ...  \n",
       "88                                                NaN  \n",
       "89                                                NaN  \n",
       "90  [{'word': 'Yeah,', 'index_in_transcript': 0}, ...  \n",
       "91                                                 []  \n",
       "92  [{'word': 'So', 'index_in_transcript': 0}, {'w...  \n",
       "\n",
       "[93 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>language_code</th>\n",
       "      <th>confidence</th>\n",
       "      <th>speaker_tag</th>\n",
       "      <th>transcript_csv</th>\n",
       "      <th>hashed_transcript</th>\n",
       "      <th>transcript_json</th>\n",
       "      <th>less_confident_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.8</td>\n",
       "      <td>14.5</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.96046</td>\n",
       "      <td>1</td>\n",
       "      <td>Can you just speak to what it takes for great ...</td>\n",
       "      <td>a5350f3f9dfe18a3401a06f9972b31bab70158e3bed551...</td>\n",
       "      <td>Can you just speak to what it takes for great ...</td>\n",
       "      <td>[{'word': 'the', 'index_in_transcript': 19}, {...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.4</td>\n",
       "      <td>18.1</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.84458</td>\n",
       "      <td>1</td>\n",
       "      <td>process of the process of constantly improvin...</td>\n",
       "      <td>7765622ac3bfe9d45ebd6d1418c06e5f34fe2726ad6190...</td>\n",
       "      <td>process of the process of constantly improvin...</td>\n",
       "      <td>[{'word': 'of', 'index_in_transcript': 1}, {'w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.9</td>\n",
       "      <td>29.3</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.82285</td>\n",
       "      <td>2</td>\n",
       "      <td>Well, these are to say simplify as vertical t...</td>\n",
       "      <td>f244266073005f037d09105a548175753ed8d105419285...</td>\n",
       "      <td>Well, these are to say simplify as vertical t...</td>\n",
       "      <td>[{'word': 'these', 'index_in_transcript': 1}, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.7</td>\n",
       "      <td>41.8</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.88606</td>\n",
       "      <td>2</td>\n",
       "      <td>You know how this very basic first basic firs...</td>\n",
       "      <td>6cdc50f14fc9676f34f8dcb7ce5fec772d6e77a844236e...</td>\n",
       "      <td>You know how this very basic first basic firs...</td>\n",
       "      <td>[{'word': 'how', 'index_in_transcript': 2}, {'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.3</td>\n",
       "      <td>48.9</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.72278</td>\n",
       "      <td>2</td>\n",
       "      <td>The requirements always down to some degree. ...</td>\n",
       "      <td>ac34c4be5f95eb462a15976a7445f3c91c2dd8b24e586f...</td>\n",
       "      <td>The requirements always down to some degree. ...</td>\n",
       "      <td>[{'word': 'The', 'index_in_transcript': 0}, {'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>489.4</td>\n",
       "      <td>497.2</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.83681</td>\n",
       "      <td>2</td>\n",
       "      <td>look at the gray matter, which is the compute...</td>\n",
       "      <td>3c0ab2fae4413f984ce660e62cc68cd594907607e88449...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>497.2</td>\n",
       "      <td>502.1</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.83681</td>\n",
       "      <td>1</td>\n",
       "      <td>like walking around in the super computer cen...</td>\n",
       "      <td>20078ff5635fc66c05669d581f7e12cdce2e95dbabe8de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>502.8</td>\n",
       "      <td>503.1</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.53844</td>\n",
       "      <td>1</td>\n",
       "      <td>Yeah, well.</td>\n",
       "      <td>63ba1f77d332ea3b44f03b603d5061b69e9b8a599c1278...</td>\n",
       "      <td>Yeah, well.</td>\n",
       "      <td>[{'word': 'Yeah,', 'index_in_transcript': 0}, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>504.1</td>\n",
       "      <td>505.5</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.90823</td>\n",
       "      <td>1</td>\n",
       "      <td>one day build a super intelligent</td>\n",
       "      <td>66f6b248588f96d27582131f394fde8035d9d5916b3571...</td>\n",
       "      <td>one day build a super intelligent</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>506.7</td>\n",
       "      <td>507.8</td>\n",
       "      <td>en-us</td>\n",
       "      <td>0.70052</td>\n",
       "      <td>1</td>\n",
       "      <td>So super super intelligence system.</td>\n",
       "      <td>3aba776bd932b4f07c4d785d5a0e66513b84b505df8e34...</td>\n",
       "      <td>So super super intelligence system.</td>\n",
       "      <td>[{'word': 'So', 'index_in_transcript': 0}, {'w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 9 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Changing less confident words and combining the transcript into one conversation",
   "id": "16d5619be5649ef8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T07:30:36.956182Z",
     "start_time": "2024-08-17T07:30:36.899895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Combining the transcript into one conversation\n",
    "less_confident_words_list = []\n",
    "transcript_list = []\n",
    "\n",
    "row_start_index = 0\n",
    "transcript_itm = \"\"\n",
    "less_confident_words_itm = []\n",
    "prev_speaker_tag = None\n",
    "\n",
    "for idx, row in transcript_merged_df.iterrows():\n",
    "    if prev_speaker_tag is None or prev_speaker_tag == row['speaker_tag']:\n",
    "        transcript_itm += row['transcript_csv'].strip() + \" \"\n",
    "\n",
    "        if not pd.isnull(row['less_confident_words']):\n",
    "            row_less_confident_words_list = eval(row['less_confident_words'])\n",
    "            for word in row_less_confident_words_list:\n",
    "                less_confident_words_itm.append({\n",
    "                    'word': word['word'],\n",
    "                    'index_in_transcript': row_start_index + word['index_in_transcript']\n",
    "                })\n",
    "    else:\n",
    "        transcript_list.append({\n",
    "            'speaker_tag': prev_speaker_tag,\n",
    "            'transcript': transcript_itm.strip()\n",
    "        })\n",
    "        transcript_itm = row['transcript_csv'] + \" \"\n",
    "\n",
    "        less_confident_words_list.append(less_confident_words_itm)\n",
    "        less_confident_words_itm = []\n",
    "        row_start_index = 0\n",
    "        if not pd.isnull(row['less_confident_words']):\n",
    "            row_less_confident_words_list = eval(row['less_confident_words'])\n",
    "            for word in row_less_confident_words_list:\n",
    "                less_confident_words_itm.append({\n",
    "                    'word': word['word'],\n",
    "                    'index_in_transcript': row_start_index + word['index_in_transcript']\n",
    "                })\n",
    "\n",
    "    # row_start_index = 1 if row_start_index == 0 else row_start_index  # this is needed when we compare the index of words in the transcript\n",
    "    row_start_index += (len(row['transcript_csv'].split(\" \")) - 1)\n",
    "    prev_speaker_tag = row['speaker_tag']\n",
    "\n",
    "transcript_list.append({\n",
    "    'speaker_tag': prev_speaker_tag,\n",
    "    'transcript': transcript_itm.strip()\n",
    "})\n",
    "less_confident_words_list.append(less_confident_words_itm)\n",
    "\n",
    "print(f\"len(less_confident_words_list) :- {len(less_confident_words_list)}\")\n",
    "less_confident_words_list"
   ],
   "id": "41200ea26d04bdc2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(less_confident_words_list) :- 29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'word': 'the', 'index_in_transcript': 19},\n",
       "  {'word': 'supercomputer', 'index_in_transcript': 20},\n",
       "  {'word': 'is', 'index_in_transcript': 22},\n",
       "  {'word': 'of', 'index_in_transcript': 30},\n",
       "  {'word': 'the', 'index_in_transcript': 31},\n",
       "  {'word': 'of', 'index_in_transcript': 33}],\n",
       " [{'word': 'these', 'index_in_transcript': 1},\n",
       "  {'word': 'are', 'index_in_transcript': 2},\n",
       "  {'word': 'as', 'index_in_transcript': 6},\n",
       "  {'word': 'how', 'index_in_transcript': 13},\n",
       "  {'word': 'first', 'index_in_transcript': 17},\n",
       "  {'word': 'first', 'index_in_transcript': 19},\n",
       "  {'word': 'the', 'index_in_transcript': 36},\n",
       "  {'word': 'The', 'index_in_transcript': 41},\n",
       "  {'word': 'down', 'index_in_transcript': 44},\n",
       "  {'word': 'to', 'index_in_transcript': 45},\n",
       "  {'word': 'some', 'index_in_transcript': 46},\n",
       "  {'word': 'if', 'index_in_transcript': 49},\n",
       "  {'word': 'want', 'index_in_transcript': 51},\n",
       "  {'word': 'to', 'index_in_transcript': 52},\n",
       "  {'word': 'Sorrow', 'index_in_transcript': 53},\n",
       "  {'word': 'by', 'index_in_transcript': 54},\n",
       "  {'word': 'reducing', 'index_in_transcript': 55},\n",
       "  {'word': 'And', 'index_in_transcript': 60},\n",
       "  {'word': 'nobody', 'index_in_transcript': 61},\n",
       "  {'word': 'how', 'index_in_transcript': 62},\n",
       "  {'word': 'smart', 'index_in_transcript': 63},\n",
       "  {'word': 'person', 'index_in_transcript': 64},\n",
       "  {'word': 'is', 'index_in_transcript': 65},\n",
       "  {'word': 'gave', 'index_in_transcript': 66},\n",
       "  {'word': 'you', 'index_in_transcript': 67},\n",
       "  {'word': 'this', 'index_in_transcript': 70},\n",
       "  {'word': 'little', 'index_in_transcript': 71},\n",
       "  {'word': 'dumb', 'index_in_transcript': 72},\n",
       "  {'word': 'just', 'index_in_transcript': 73},\n",
       "  {'word': 'under', 'index_in_transcript': 74},\n",
       "  {'word': 'three.', 'index_in_transcript': 75},\n",
       "  {'word': 'If', 'index_in_transcript': 76},\n",
       "  {'word': 'to', 'index_in_transcript': 79},\n",
       "  {'word': 'answer', 'index_in_transcript': 89},\n",
       "  {'word': 'Though', 'index_in_transcript': 94},\n",
       "  {'word': 'that', 'index_in_transcript': 108},\n",
       "  {'word': 'these', 'index_in_transcript': 122},\n",
       "  {'word': 'the', 'index_in_transcript': 125},\n",
       "  {'word': 'delete', 'index_in_transcript': 143},\n",
       "  {'word': 'if', 'index_in_transcript': 147},\n",
       "  {'word': \"it's\", 'index_in_transcript': 166},\n",
       "  {'word': 'an', 'index_in_transcript': 167},\n",
       "  {'word': 'a', 'index_in_transcript': 170},\n",
       "  {'word': 'some', 'index_in_transcript': 171},\n",
       "  {'word': 'feel', 'index_in_transcript': 178},\n",
       "  {'word': 'their', 'index_in_transcript': 192},\n",
       "  {'word': 'And', 'index_in_transcript': 229},\n",
       "  {'word': 'it', 'index_in_transcript': 230},\n",
       "  {'word': 'sounds', 'index_in_transcript': 231},\n",
       "  {'word': 'just', 'index_in_transcript': 232},\n",
       "  {'word': 'these', 'index_in_transcript': 233},\n",
       "  {'word': 'all', 'index_in_transcript': 234},\n",
       "  {'word': 'sound', 'index_in_transcript': 235},\n",
       "  {'word': 'of', 'index_in_transcript': 248},\n",
       "  {'word': 'is', 'index_in_transcript': 254},\n",
       "  {'word': 'care', 'index_in_transcript': 258},\n",
       "  {'word': 'have', 'index_in_transcript': 264},\n",
       "  {'word': 'a', 'index_in_transcript': 265},\n",
       "  {'word': 'sponsor.', 'index_in_transcript': 266}],\n",
       " [{'word': 'Right.', 'index_in_transcript': 0},\n",
       "  {'word': 'you', 'index_in_transcript': 2},\n",
       "  {'word': 'did', 'index_in_transcript': 4},\n",
       "  {'word': 'shoot', 'index_in_transcript': 14},\n",
       "  {'word': 'super', 'index_in_transcript': 24},\n",
       "  {'word': 'computer', 'index_in_transcript': 25},\n",
       "  {'word': 'this', 'index_in_transcript': 34}],\n",
       " [{'word': 'Try', 'index_in_transcript': 0},\n",
       "  {'word': 'Yeah,', 'index_in_transcript': 6},\n",
       "  {'word': 'What', 'index_in_transcript': 16},\n",
       "  {'word': 'to', 'index_in_transcript': 25}],\n",
       " [],\n",
       " [{'word': 'them', 'index_in_transcript': 57},\n",
       "  {'word': 'And', 'index_in_transcript': 59},\n",
       "  {'word': 'they', 'index_in_transcript': 61},\n",
       "  {'word': 'over', 'index_in_transcript': 72},\n",
       "  {'word': 'complicated', 'index_in_transcript': 73},\n",
       "  {'word': 'in', 'index_in_transcript': 81},\n",
       "  {'word': 'a', 'index_in_transcript': 82},\n",
       "  {'word': 'word', 'index_in_transcript': 83},\n",
       "  {'word': 'gonna', 'index_in_transcript': 85},\n",
       "  {'word': 'Than', 'index_in_transcript': 88},\n",
       "  {'word': 'going', 'index_in_transcript': 103},\n",
       "  {'word': 'to', 'index_in_transcript': 104}],\n",
       " [{'word': 'the', 'index_in_transcript': 18}],\n",
       " [{'word': 'people', 'index_in_transcript': 23},\n",
       "  {'word': 'get', 'index_in_transcript': 24},\n",
       "  {'word': 'shocked', 'index_in_transcript': 27},\n",
       "  {'word': 'by', 'index_in_transcript': 28},\n",
       "  {'word': 'got', 'index_in_transcript': 62},\n",
       "  {'word': 'over', 'index_in_transcript': 63}],\n",
       " [{'word': 'One', 'index_in_transcript': 0},\n",
       "  {'word': 'of', 'index_in_transcript': 1},\n",
       "  {'word': 'that', 'index_in_transcript': 3},\n",
       "  {'word': 'leads', 'index_in_transcript': 5},\n",
       "  {'word': 'us', 'index_in_transcript': 6},\n",
       "  {'word': 'astray.', 'index_in_transcript': 7}],\n",
       " [{'word': 'I', 'index_in_transcript': 13},\n",
       "  {'word': 'have', 'index_in_transcript': 14},\n",
       "  {'word': 'the', 'index_in_transcript': 27},\n",
       "  {'word': 'is', 'index_in_transcript': 29},\n",
       "  {'word': 'It', 'index_in_transcript': 32},\n",
       "  {'word': \"it's\", 'index_in_transcript': 45},\n",
       "  {'word': 'you', 'index_in_transcript': 49},\n",
       "  {'word': 'try', 'index_in_transcript': 50},\n",
       "  {'word': 'and', 'index_in_transcript': 54},\n",
       "  {'word': 'speeding', 'index_in_transcript': 58},\n",
       "  {'word': \"That's\", 'index_in_transcript': 60},\n",
       "  {'word': 'speeding', 'index_in_transcript': 63},\n",
       "  {'word': 'as', 'index_in_transcript': 69},\n",
       "  {'word': 'if', 'index_in_transcript': 70},\n",
       "  {'word': 'so,', 'index_in_transcript': 71},\n",
       "  {'word': 'then', 'index_in_transcript': 73},\n",
       "  {'word': 'And', 'index_in_transcript': 81},\n",
       "  {'word': 'backwards', 'index_in_transcript': 84},\n",
       "  {'word': 'where', 'index_in_transcript': 88},\n",
       "  {'word': 'sped', 'index_in_transcript': 92},\n",
       "  {'word': 'Simplified', 'index_in_transcript': 95},\n",
       "  {'word': 'and', 'index_in_transcript': 97},\n",
       "  {'word': 'then', 'index_in_transcript': 98},\n",
       "  {'word': 'delete', 'index_in_transcript': 99},\n",
       "  {'word': 'And', 'index_in_transcript': 101},\n",
       "  {'word': 'I', 'index_in_transcript': 102},\n",
       "  {'word': 'of', 'index_in_transcript': 105}],\n",
       " [],\n",
       " [],\n",
       " [{'word': 'in', 'index_in_transcript': 11},\n",
       "  {'word': 'a', 'index_in_transcript': 12},\n",
       "  {'word': 'hand', 'index_in_transcript': 13},\n",
       "  {'word': 'well', 'index_in_transcript': 14}],\n",
       " [{'word': 'want', 'index_in_transcript': 7},\n",
       "  {'word': 'to', 'index_in_transcript': 8},\n",
       "  {'word': 'corks.', 'index_in_transcript': 12},\n",
       "  {'word': 'In', 'index_in_transcript': 13},\n",
       "  {'word': 'fact,', 'index_in_transcript': 14},\n",
       "  {'word': 'I', 'index_in_transcript': 15}],\n",
       " [{'word': 'So', 'index_in_transcript': 0},\n",
       "  {'word': 'yes.', 'index_in_transcript': 1}],\n",
       " [{'word': 'a', 'index_in_transcript': 5},\n",
       "  {'word': \"you've\", 'index_in_transcript': 12},\n",
       "  {'word': 'all', 'index_in_transcript': 13},\n",
       "  {'word': 'that', 'index_in_transcript': 19},\n",
       "  {'word': 'where', 'index_in_transcript': 20},\n",
       "  {'word': 'is', 'index_in_transcript': 23},\n",
       "  {'word': 'I', 'index_in_transcript': 26},\n",
       "  {'word': 'can', 'index_in_transcript': 27},\n",
       "  {'word': \"it's\", 'index_in_transcript': 30},\n",
       "  {'word': 'and', 'index_in_transcript': 35},\n",
       "  {'word': 'then', 'index_in_transcript': 36},\n",
       "  {'word': 'silence', 'index_in_transcript': 43},\n",
       "  {'word': 'it', 'index_in_transcript': 48},\n",
       "  {'word': 'subsequent.', 'index_in_transcript': 49},\n",
       "  {'word': 'And', 'index_in_transcript': 50},\n",
       "  {'word': 'then', 'index_in_transcript': 51},\n",
       "  {'word': 'the', 'index_in_transcript': 52},\n",
       "  {'word': 'kind', 'index_in_transcript': 55},\n",
       "  {'word': '10', 'index_in_transcript': 68},\n",
       "  {'word': '20', 'index_in_transcript': 69},\n",
       "  {'word': 'megawatts.', 'index_in_transcript': 70}],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [{'word': 'Jitter', 'index_in_transcript': 1}],\n",
       " [],\n",
       " [{'word': 'Yeah', 'index_in_transcript': 5},\n",
       "  {'word': 'there', 'index_in_transcript': 6},\n",
       "  {'word': 'we', 'index_in_transcript': 7},\n",
       "  {'word': 'got', 'index_in_transcript': 10},\n",
       "  {'word': 'it', 'index_in_transcript': 11},\n",
       "  {'word': 'to', 'index_in_transcript': 12},\n",
       "  {'word': 'go', 'index_in_transcript': 13},\n",
       "  {'word': 'Allina', 'index_in_transcript': 17},\n",
       "  {'word': 'for', 'index_in_transcript': 19},\n",
       "  {'word': '4:20', 'index_in_transcript': 20},\n",
       "  {'word': 'a.m.', 'index_in_transcript': 21}],\n",
       " [{'word': 'remove', 'index_in_transcript': 5},\n",
       "  {'word': 'the', 'index_in_transcript': 6},\n",
       "  {'word': '422.', 'index_in_transcript': 7},\n",
       "  {'word': 'with', 'index_in_transcript': 13},\n",
       "  {'word': 'you?', 'index_in_transcript': 14},\n",
       "  {'word': 'the', 'index_in_transcript': 51},\n",
       "  {'word': 'understand', 'index_in_transcript': 56},\n",
       "  {'word': 'Understands', 'index_in_transcript': 60},\n",
       "  {'word': 'it', 'index_in_transcript': 61},\n",
       "  {'word': 'is', 'index_in_transcript': 68},\n",
       "  {'word': 'or', 'index_in_transcript': 70},\n",
       "  {'word': 'is', 'index_in_transcript': 73},\n",
       "  {'word': 'inefficient', 'index_in_transcript': 74},\n",
       "  {'word': 'or', 'index_in_transcript': 75},\n",
       "  {'word': 'that', 'index_in_transcript': 76},\n",
       "  {'word': 'yeah.', 'index_in_transcript': 77},\n",
       "  {'word': 'you', 'index_in_transcript': 79},\n",
       "  {'word': 'to', 'index_in_transcript': 81},\n",
       "  {'word': 'that?', 'index_in_transcript': 82}],\n",
       " [{'word': 'I', 'index_in_transcript': 2},\n",
       "  {'word': 'like', 'index_in_transcript': 3},\n",
       "  {'word': 'I', 'index_in_transcript': 4},\n",
       "  {'word': 'the', 'index_in_transcript': 12},\n",
       "  {'word': 'front', 'index_in_transcript': 13},\n",
       "  {'word': 'lines', 'index_in_transcript': 14},\n",
       "  {'word': 'I', 'index_in_transcript': 17},\n",
       "  {'word': 'tried', 'index_in_transcript': 18},\n",
       "  {'word': 'it', 'index_in_transcript': 21},\n",
       "  {'word': 'King', 'index_in_transcript': 29},\n",
       "  {'word': 'Fiber', 'index_in_transcript': 30},\n",
       "  {'word': 'Optic', 'index_in_transcript': 31},\n",
       "  {'word': 'Pulte', 'index_in_transcript': 35},\n",
       "  {'word': 'but', 'index_in_transcript': 37},\n",
       "  {'word': 'to', 'index_in_transcript': 40},\n",
       "  {'word': 'the', 'index_in_transcript': 42},\n",
       "  {'word': 'limiting', 'index_in_transcript': 43},\n",
       "  {'word': 'launch', 'index_in_transcript': 46},\n",
       "  {'word': 'clusters', 'index_in_transcript': 48},\n",
       "  {'word': 'is', 'index_in_transcript': 49},\n",
       "  {'word': 'caveling.', 'index_in_transcript': 51},\n",
       "  {'word': 'so', 'index_in_transcript': 52},\n",
       "  {'word': 'cables', 'index_in_transcript': 54},\n",
       "  {'word': 'um', 'index_in_transcript': 55},\n",
       "  {'word': 'because', 'index_in_transcript': 56},\n",
       "  {'word': 'for', 'index_in_transcript': 57},\n",
       "  {'word': 'of', 'index_in_transcript': 60},\n",
       "  {'word': 'so', 'index_in_transcript': 67},\n",
       "  {'word': 'one', 'index_in_transcript': 77},\n",
       "  {'word': 'giant', 'index_in_transcript': 78},\n",
       "  {'word': '100,000.', 'index_in_transcript': 100},\n",
       "  {'word': 'That', 'index_in_transcript': 101},\n",
       "  {'word': 'was', 'index_in_transcript': 102}],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [{'word': 'Yeah,', 'index_in_transcript': 15},\n",
       "  {'word': 'well.', 'index_in_transcript': 16},\n",
       "  {'word': 'So', 'index_in_transcript': 23},\n",
       "  {'word': 'super', 'index_in_transcript': 24},\n",
       "  {'word': 'super', 'index_in_transcript': 25}]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T07:30:37.426920Z",
     "start_time": "2024-08-17T07:30:37.410908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"len(transcript_list) :- {len(transcript_list)}\")\n",
    "transcript_list"
   ],
   "id": "25ae181c3ae3b041",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(transcript_list) :- 29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'speaker_tag': 1,\n",
       "  'transcript': 'Can you just speak to what it takes for great engineering team for you? What I saw in Memphis the supercomputer cluster is just this intense drive towards simplifying the process of the process of constantly improving it constantly iterating it.'},\n",
       " {'speaker_tag': 2,\n",
       "  'transcript': \"Well, these are to say simplify as vertical to do it. You know how this very basic first basic first principles algorithm that I run kind of as like a mantra which is the first question the requirements make the requirements. The requirements always down to some degree. So if you want to Sorrow by reducing the number of requirements. And nobody how smart person is gave you those requirements this little dumb just under three. If you have to start there because otherwise you could get the perfect answer to the wrong question. Though so try to make the question the least wrong possible. That's what question that requirements means and then the second thing is try to delete the whatever these step is the part or the process step sounds very obvious, but people often forget to do to try to delete it entirely and if you're not forced to put back at least 10% of what you delete, you're not deleting enough like it's an and it's a some illogically people often. Most the time feel as though they have succeeded if they have not been forced to put their put things back in but actually they haven't because they've been overly conservative and have left things in there. That shouldn't be so and only the third thing is try to optimize it or simplify it. And it sounds just these all sound I think very very obvious when I say them but the number of times I've made these mistakes is more than I care to remember. That's why I have a sponsor. So in fact, I'd say the most common mistake of smart Engineers is to optimize a thing. That should not exist.\"},\n",
       " {'speaker_tag': 1,\n",
       "  'transcript': 'Right. So you like did you say you run through the algorithm? Yeah, basically shoot show up to a problem show up to the super computer cluster and see the process and ask can this be deleted?'},\n",
       " {'speaker_tag': 2,\n",
       "  'transcript': \"Try to delete it. Yeah. Yeah. Yeah, that's not easy to do know and actually this. What generally makes people uneasy is that you've got to delete at least? things that you delete you will put back in. Yeah,\"},\n",
       " {'speaker_tag': 1, 'transcript': 'but'},\n",
       " {'speaker_tag': 2,\n",
       "  'transcript': \"going back to sort of where Olympics system can steer us wrong is that we tend to remember with it. Sometimes a jarring level of pain where we where we deleted something that we subsequently needed. And so people will remember that one time they've got to put in this thing three years ago, and that caused them trouble. And so they overcorrect and then they put too much stuff in their over complicated things. So he actually have to say in a word deliberately gonna delete more. Than we we should so that we're putting at least one in 10 things. We're going to add back in.\"},\n",
       " {'speaker_tag': 1,\n",
       "  'transcript': \"And I've seen you suggest just that that something should be deleted and you can kind of see the the pain. Oh, yeah, absolutely. Everybody feels a little bit of the pain.\"},\n",
       " {'speaker_tag': 2,\n",
       "  'transcript': \"Absolutely and I told me in advance like yeah, there's some of the things that we delete we're going to put back in. people get a little shocked by that but it makes sense because if you if you're so conservative as to never have to put anything back in you obviously have a lot of stuff that isn't needed. So you got over correct? This is I would say like a cortical override to Olympic instinct.\"},\n",
       " {'speaker_tag': 1,\n",
       "  'transcript': \"One of many that probably leads us astray. Yeah. Yeah. There's like a\"},\n",
       " {'speaker_tag': 2,\n",
       "  'transcript': \"step for as well, which is any given thing can be sped up. I have a fast you think it can be done like whatever the speed the speed is being done. It can be done faster. But but you shouldn't speak things up until it's soft and until you try to delete it and optimize. Otherwise, you're speeding up. That's something that speeding up something that shouldn't exist as if so, and then the first thing is to automate it. And I've gone backwards so many times where I've automated something sped it up. Simplified it and then delete it. And I got tired of doing that. Why I've got this Mantra that is a very effective\"},\n",
       " {'speaker_tag': 1,\n",
       "  'transcript': \"five-step process of works. Great. Well when you were already automated deleting must be real painful. Yeah, if yeah, that's great. It's\"},\n",
       " {'speaker_tag': 2,\n",
       "  'transcript': \"like it's like wow, I really wasted a lot of effort there. Yeah.\"},\n",
       " {'speaker_tag': 1,\n",
       "  'transcript': 'Done with the with the cluster in Memphis is incredible just in a hand well weeks.'},\n",
       " {'speaker_tag': 2,\n",
       "  'transcript': \"Yeah, it's not working yet. So I want to pop the champagne corks. In fact, I have a call in a few hours with the Memphis team. Because we're having some power fluctuation issues.\"},\n",
       " {'speaker_tag': 1, 'transcript': 'So yes.'},\n",
       " {'speaker_tag': 2,\n",
       "  'transcript': \"Yeah, it's kind of there's a when you do. Synchronize training when you've all these computers that are training. that where the training is synchronized to I can level. you it's like having an orchestra and then the orchestra can go loud to silence very quickly, you know it subsequent. And then the electrical system kind of freaks out about that. Like if you suddenly see giant shifts 10 20 megawatts. So several times a second the this is not what electrical systems are expecting to see\"},\n",
       " {'speaker_tag': 1,\n",
       "  'transcript': \"so that's one of the main things you have to figure out the cooling the power the and then on the software as you go up the stack to do. Yeah, the distributed compute all that today's\"},\n",
       " {'speaker_tag': 2, 'transcript': 'problem is dealing with'},\n",
       " {'speaker_tag': 1, 'transcript': 'with'},\n",
       " {'speaker_tag': 2, 'transcript': 'power Jitter power Jitter. Yeah'},\n",
       " {'speaker_tag': 1,\n",
       "  'transcript': \"a nice ring to that. So that's okay and you stayed up late into the night as you often do\"},\n",
       " {'speaker_tag': 2,\n",
       "  'transcript': 'their last weekend last week. Yeah there we finally finally got it to go training going at Allina roughly for 4:20 a.m. Last Monday.'},\n",
       " {'speaker_tag': 1,\n",
       "  'transcript': \"Total coincidence. Yeah, I mean remove the 422. Yeah, is that Universe again with you? Just love it. I mean Yeah, I wonder if you could speak. One of the things that you did when I was there as you went through all the steps of whatever he's doing just get the sense that you yourself understand it and everybody. Understands it so they can understand when something is dumb or something. Something is inefficient or that yeah. Can you speak to that?\"},\n",
       " {'speaker_tag': 2,\n",
       "  'transcript': \"yeah, so I like I try to do whatever the people at the front lines are doing I tried to do it at least a few times myself, so King Fiber Optic Cables diagnosing a Pulte connection, but that tends to be the limiting factor for launch training clusters is the caveling. so many cables um because for for coherence of training system where you've got RDMA so remote direct memory access the whole thing is like one giant brain. So if you've got any to any connection, so it's the any GPU can talk to any GPU out of 100,000. That was a crazy cable layout. It looks pretty cool. Yeah, it's like\"},\n",
       " {'speaker_tag': 1,\n",
       "  'transcript': \"it's like the human brain but like at a scale that humans can visibly see it is. Yeah, right.\"},\n",
       " {'speaker_tag': 2,\n",
       "  'transcript': 'I mean here in brain also has a massive amount of the brain tissue is the cables.'},\n",
       " {'speaker_tag': 1, 'transcript': 'Yeah. So'},\n",
       " {'speaker_tag': 2,\n",
       "  'transcript': \"look at the gray matter, which is the computer and then the white matter which is cables big percentage of your brain is just capables that's\"},\n",
       " {'speaker_tag': 1,\n",
       "  'transcript': 'like walking around in the super computer center is like walking around inside the brain Yeah, well. one day build a super intelligent So super super intelligence system.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T07:30:38.078934Z",
     "start_time": "2024-08-17T07:30:38.060524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "podcast_name = \"Lex Fridman Podcast\"\n",
    "podcast_topic = \"Elon Musk's approach to problem-solving\"\n",
    "podcast_people = \"Lex Fridman, Elon Musk\"\n",
    "\n",
    "# transcript = \"And nobody how smart person is gave you those requirements this little dumb just under three.\"\n",
    "# less_confident_words = \"[{'word': 'And', 'index_in_transcript': 0}, {'word': 'nobody', 'index_in_transcript': 1}, {'word': 'how', 'index_in_transcript': 2}, {'word': 'smart', 'index_in_transcript': 3}, {'word': 'person', 'index_in_transcript': 4}, {'word': 'is', 'index_in_transcript': 5}, {'word': 'gave', 'index_in_transcript': 6}, {'word': 'you', 'index_in_transcript': 7}, {'word': 'this', 'index_in_transcript': 10}, {'word': 'little', 'index_in_transcript': 11}, {'word': 'dumb', 'index_in_transcript': 12}, {'word': 'just', 'index_in_transcript': 13}, {'word': 'under', 'index_in_transcript': 14}, {'word': 'three.', 'index_in_transcript': 15}]\""
   ],
   "id": "b9e074ba5f602ed",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T07:30:38.753553Z",
     "start_time": "2024-08-17T07:30:38.739563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('vars.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "openai_api_key = data[\"open_ai_api_key\"]\n",
    "langchain_api_key = data[\"langchain_api_key\"]\n",
    "# tavily_api_key = data[\"tavily_api_key\"]\n",
    "groq_api_key = data[\"groq_api_key\"]"
   ],
   "id": "62d8f19d15eb2451",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T07:30:46.094176Z",
     "start_time": "2024-08-17T07:30:42.102053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_agents._models import get_llm\n",
    "\n",
    "llm_llama3 = get_llm(llm_type='llama3', llm_model='llama3-70b-8192', api_key=groq_api_key)\n",
    "llm_gpt = get_llm(llm_type='gpt', llm_model='gpt-4o-mini', api_key=openai_api_key)"
   ],
   "id": "45563d5cc48d0180",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T07:30:46.109887Z",
     "start_time": "2024-08-17T07:30:46.099114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "class SingleTranscript(BaseModel):\n",
    "    \"\"\"\n",
    "    The piece of transcript with the speaker identification\n",
    "    \"\"\"\n",
    "    speaker_id: int = Field(description=\"Speaker identification number\")\n",
    "    transcript_str: str = Field(description=\"The piece of transcript the speaker said.\")   \n",
    "\n",
    "\n",
    "class HandleLessConfidentWordsOutput(BaseModel):\n",
    "    \"\"\"\n",
    "    The output transcript.\n",
    "    \"\"\"\n",
    "    transcript: List[SingleTranscript] = Field(\n",
    "        description=\"The list of piece of changed transcripts with the speaker identification.\"\n",
    "    )\n",
    "    considerations: List[str] = Field([], description=\"A list things you considered when changing the transcript.\")\n",
    "    actions: List[str] = Field([], description=\"A list of actions you took to change the transcript.\")"
   ],
   "id": "ab2d4b3d8d03893d",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T07:30:46.916719Z",
     "start_time": "2024-08-17T07:30:46.114900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "handle_less_confident_words_system_prompt = f\"\"\"\\\n",
    "You are an expert at casual, conversational english language. \\\n",
    "You have been provided with a transcript of a podcast between two people. \\\n",
    "The transcript has been generated using Google Speech-to-Text. \\\n",
    "\n",
    "Information about podcast: \\\n",
    "1. Name of the podcast: \"{podcast_name}\" \\\n",
    "2. Topic of the podcast: \"{podcast_topic}\" \\\n",
    "3. People in the podcast: \"{podcast_people}\" \\\n",
    "\n",
    "You have been provided with these: \\\n",
    "{{less_confident_words}} - less_confident_words_list (a list of lists of json objects). \\\n",
    "                           Each json object has two keys: word (the less confident word) and index_in_transcript (the index of the word in the transcript. index of the first word in the transcript is 0). \\\n",
    "                           Some internal lists can be empty. \\\n",
    "                           That means Google Speech-to-Text has not provided less confident words for the corresponding transcript. \\\n",
    "{{transcript}} - transcript_list (a list of json objects) \\\n",
    "                 Each json object has two keys: speaker_tag (the speaker identification number) and transcript (the piece of dialog the speaker said. This can be half of sentences and phrases.) \\\n",
    "\n",
    "i th item in less_confident_words_list corresponds to i th item in transcript_list. \\\n",
    "\n",
    "Follow these steps to make the original transcript better and provide the changed transcript : \\\n",
    "1. Go through the transcript and less_confident_words_list. \\\n",
    "2. You have to figure out words in the less_confident_words_list has to be changed or not to fit into the context. \\\n",
    "3. Identify the less confident words in the transcript which are not given in the less_confident_words_list, if there are any and change them to fit into the context. \\\n",
    "4. If you think the word has to be changed, you have to change it to a more suitable word. \\\n",
    "5. You have to make the transcript sound more natural. \\\n",
    "6. You have to make sure that the transcript is coherent and the words are in the right context. \\\n",
    "7. You have to make sure that each transcript makes sense. \\\n",
    "8. Provide the changed transcript after following the above steps, a list things you considered when changing the transcript and a list of actions you took to change the transcript. \\\n",
    "\"\"\"\n",
    "\n",
    "handle_less_confident_words_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", handle_less_confident_words_system_prompt),\n",
    "        (\"human\", \"The less_confident_words is : {{less_confident_words}}. The transcript is : {{transcript}}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = handle_less_confident_words_prompt | llm_gpt.with_structured_output(schema=HandleLessConfidentWordsOutput)\n",
    "# chain = handle_less_confident_words_prompt | llm_llama3.with_structured_output(schema=HandleLessConfidentWordsOutput)\n",
    "# chain = handle_less_confident_words_prompt | llm_llama3 | StrOutputParser()"
   ],
   "id": "49d8fe3b19375a8",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T07:31:10.090437Z",
     "start_time": "2024-08-17T07:30:48.439655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = chain.invoke({\n",
    "    \"less_confident_words\": less_confident_words_list,\n",
    "    \"transcript\": transcript_list\n",
    "})"
   ],
   "id": "4b120d5e33691032",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T07:31:10.121393Z",
     "start_time": "2024-08-17T07:31:10.095362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for idx, transcript in enumerate(result.transcript):\n",
    "    print(transcript.__dict__)\n",
    "\n",
    "# print(result)"
   ],
   "id": "8046b0112c7725cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'speaker_id': 1, 'transcript_str': 'Can you just speak to what it takes for a great engineering team for you? What I saw in Memphis, the supercomputer cluster is just this intense drive towards simplifying the process and constantly improving it, constantly iterating it.'}\n",
      "{'speaker_id': 2, 'transcript_str': \"Well, these are to say simplify as vertical to do it. You know how this very basic first principles algorithm that I run kind of as like a mantra, which is the first question: the requirements. Make the requirements. The requirements always come down to some degree. So if you want to reduce sorrow by reducing the number of requirements. And nobody, no matter how smart a person is, gave you those requirements, this little dumb just under three. If you have to start there because otherwise you could get the perfect answer to the wrong question. So try to make the question the least wrong possible. That's what the question that requirements means. And then the second thing is try to delete whatever these steps are, the part or the process step. Sounds very obvious, but people often forget to do it. Try to delete it entirely, and if you're not forced to put back at least 10% of what you delete, you're not deleting enough. It's some illogical thing that people often feel as though they have succeeded if they have not been forced to put things back in, but actually they haven't because they've been overly conservative and have left things in there that shouldn't be. And only the third thing is try to optimize it or simplify it. And it sounds just these all sound, I think, very, very obvious when I say them, but the number of times I've made these mistakes is more than I care to remember. That's why I have a sponsor. So in fact, I'd say the most common mistake of smart engineers is to optimize a thing that should not exist.\"}\n",
      "{'speaker_id': 1, 'transcript_str': 'Right. So you like did you say you run through the algorithm? Yeah, basically show up to a problem, show up to the supercomputer cluster and see the process and ask, can this be deleted?'}\n",
      "{'speaker_id': 2, 'transcript_str': \"Try to delete it. Yeah. Yeah. Yeah, that's not easy to do, you know? And actually this, what generally makes people uneasy is that you've got to delete at least some things that you delete you will put back in. Yeah.\"}\n",
      "{'speaker_id': 1, 'transcript_str': 'But.'}\n",
      "{'speaker_id': 2, 'transcript_str': \"Going back to sort of where our instinct can steer us wrong is that we tend to remember it sometimes with a jarring level of pain where we deleted something that we subsequently needed. And so people will remember that one time they had to put in this thing three years ago, and that caused them trouble. And so they overcorrect, and then they put too much stuff in there, overcomplicating things. So you actually have to say in a word, deliberately going to delete more than we should so that we're putting at least one in 10 things we're going to add back in.\"}\n",
      "{'speaker_id': 1, 'transcript_str': \"And I've seen you suggest just that, that something should be deleted, and you can kind of see the pain.\"}\n",
      "{'speaker_id': 2, 'transcript_str': 'Oh, yeah, absolutely. Everybody feels a little bit of the pain.'}\n",
      "{'speaker_id': 1, 'transcript_str': \"Absolutely, and I told them in advance, like yeah, there's some of the things that we delete we're going to put back in. People get a little shocked by that, but it makes sense because if you're so conservative as to never have to put anything back in, you obviously have a lot of stuff that isn't needed. So you got to overcorrect. This is, I would say, like a cortical override to our instinct.\"}\n",
      "{'speaker_id': 1, 'transcript_str': \"One of many that probably leads us astray. Yeah. Yeah. There's like a.\"}\n",
      "{'speaker_id': 2, 'transcript_str': \"Step for as well, which is any given thing can be sped up. I have a fast, you think it can be done like whatever the speed is being done. It can be done faster. But you shouldn't speed things up until it's soft and until you try to delete it and optimize. Otherwise, you're speeding up something that shouldn't exist. And then the first thing is to automate it. And I've gone backwards so many times where I've automated something, sped it up, simplified it, and then deleted it. And I got tired of doing that. Why I've got this mantra that is very effective.\"}\n",
      "{'speaker_id': 1, 'transcript_str': 'Five-step process works great. Well, when you were already automated, deleting must be real painful.'}\n",
      "{'speaker_id': 2, 'transcript_str': \"Yeah, if yeah, that's great. It's.\"}\n",
      "{'speaker_id': 1, 'transcript_str': 'Done with the cluster in Memphis is incredible just in a handful of weeks.'}\n",
      "{'speaker_id': 2, 'transcript_str': \"Yeah, it's not working yet. So I want to pop the champagne corks. In fact, I have a call in a few hours with the Memphis team because we're having some power fluctuation issues.\"}\n",
      "{'speaker_id': 1, 'transcript_str': 'So yes.'}\n",
      "{'speaker_id': 2, 'transcript_str': \"Yeah, it's kind of there's a when you do synchronize training when you've all these computers that are training, where the training is synchronized to, I can level. It's like having an orchestra, and then the orchestra can go loud to silence very quickly, you know, it subsequent. And then the electrical system kind of freaks out about that. Like if you suddenly see giant shifts, 10, 20 megawatts, several times a second, this is not what electrical systems are expecting to see.\"}\n",
      "{'speaker_id': 1, 'transcript_str': \"So that's one of the main things you have to figure out: the cooling, the power, and then on the software as you go up the stack to do. Yeah, the distributed compute, all that today's.\"}\n",
      "{'speaker_id': 2, 'transcript_str': 'Problem is dealing with.'}\n",
      "{'speaker_id': 1, 'transcript_str': 'With.'}\n",
      "{'speaker_id': 2, 'transcript_str': 'Power jitter. Power jitter. Yeah.'}\n",
      "{'speaker_id': 1, 'transcript_str': \"A nice ring to that. So that's okay, and you stayed up late into the night as you often do.\"}\n",
      "{'speaker_id': 2, 'transcript_str': 'Their last weekend, last week. Yeah, we finally got it to go training at Allina roughly for 4:20 a.m. last Monday.'}\n",
      "{'speaker_id': 1, 'transcript_str': \"Total coincidence. Yeah, I mean remove the 422. Yeah, is that Universe again with you? Just love it. I mean, yeah, I wonder if you could speak. One of the things that you did when I was there is you went through all the steps of whatever he's doing just to get the sense that you yourself understand it and everybody understands it so they can understand when something is dumb or something is inefficient or that. Yeah. Can you speak to that?\"}\n",
      "{'speaker_id': 2, 'transcript_str': \"Yeah, so I like I try to do whatever the people at the front lines are doing. I tried to do it at least a few times myself, so King Fiber Optic Cables diagnosing a Pulte connection, but that tends to be the limiting factor for launch training clusters is the cabling. So many cables, um, because for coherence of the training system where you've got RDMA, so remote direct memory access, the whole thing is like one giant brain. So if you've got any to any connection, so it's the any GPU can talk to any GPU out of 100,000. That was a crazy cable layout. It looks pretty cool.\"}\n",
      "{'speaker_id': 1, 'transcript_str': \"Yeah, it's like the human brain, but like at a scale that humans can visibly see it is. Yeah, right.\"}\n",
      "{'speaker_id': 2, 'transcript_str': 'I mean, here in the brain also has a massive amount of the brain tissue is the cables.'}\n",
      "{'speaker_id': 1, 'transcript_str': 'Yeah. So.'}\n",
      "{'speaker_id': 2, 'transcript_str': 'Look at the gray matter, which is the computer, and then the white matter, which is cables. A big percentage of your brain is just cables.'}\n",
      "{'speaker_id': 1, 'transcript_str': \"That's like walking around in the supercomputer center is like walking around inside the brain. Yeah, well, one day build a super intelligent, super super intelligence system.\"}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T07:31:10.137418Z",
     "start_time": "2024-08-17T07:31:10.127358Z"
    }
   },
   "cell_type": "code",
   "source": "print(result.considerations)",
   "id": "633b5d791a3ee278",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ensured coherence and context of the dialogue', 'Improved natural flow of conversation', 'Corrected any awkward phrasing or unclear references', 'Maintained the technical accuracy of the discussion']\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-17T07:31:10.153507Z",
     "start_time": "2024-08-17T07:31:10.142503Z"
    }
   },
   "cell_type": "code",
   "source": "print(result.actions)",
   "id": "7adfa8d64f1d67a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Changed 'Sorrow' to 'reduce sorrow' for clarity\", 'Rephrased sentences for better flow and understanding', \"Corrected 'caveling' to 'cabling' for accuracy\", 'Adjusted punctuation for better readability', 'Removed redundant phrases to streamline the dialogue']\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4344715a0be68f04"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
