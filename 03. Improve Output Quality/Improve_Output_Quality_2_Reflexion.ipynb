{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Introduction to Reflexion",
   "id": "b4a143bd8b546718"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.1 Initial Response",
   "id": "2ef672279201dc92"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T07:18:53.551197Z",
     "start_time": "2024-07-26T07:18:53.536189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "with open('vars.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "openai_api_key = data[\"open_ai_api_key\"]\n",
    "langchain_api_key = data[\"langchain_api_key\"]\n",
    "# tavily_api_key = data[\"tavily_api_key\"]\n",
    "groq_api_key = data[\"groq_api_key\"]\n",
    "\n",
    "# os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "# os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "# os.environ['LANGCHAIN_API_KEY'] = langchain_api_key"
   ],
   "id": "4b11aed2c8a90999",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T07:18:54.655601Z",
     "start_time": "2024-07-26T07:18:54.039997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setting up DB connection \n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "# Docker command to run pgvector/postgres container\n",
    "# docker run --name pgvector-container -e POSTGRES_USER=langchain -e POSTGRES_PASSWORD=langchain -e POSTGRES_DB=langchain -p 6024:5432 -d pgvector/pgvector:pg16\n",
    "db_config = {\n",
    "    'dbname': 'postgres',\n",
    "    'user': 'langchain',\n",
    "    'password': 'langchain',\n",
    "    'host': 'localhost',\n",
    "    'port': '6024'\n",
    "}\n",
    "\n",
    "connection_string = f\"postgresql+psycopg://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['dbname']}\"\n",
    "\n",
    "db = SQLDatabase.from_uri(connection_string)\n",
    "print(db.table_info)"
   ],
   "id": "61978f56f168f147",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE customer (\n",
      "\tcustomer_id SERIAL NOT NULL, \n",
      "\tname VARCHAR(100) NOT NULL, \n",
      "\tCONSTRAINT customer_pkey PRIMARY KEY (customer_id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from customer table:\n",
      "customer_id\tname\n",
      "1\tJohn Doe\n",
      "2\tJane Smith\n",
      "3\tAlice Johnson\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE feedback (\n",
      "\tfeedback_id SERIAL NOT NULL, \n",
      "\torder_id INTEGER NOT NULL, \n",
      "\tfeedback_text TEXT, \n",
      "\tCONSTRAINT feedback_pkey PRIMARY KEY (feedback_id), \n",
      "\tCONSTRAINT feedback_order_id_fkey FOREIGN KEY(order_id) REFERENCES orders (order_id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from feedback table:\n",
      "feedback_id\torder_id\tfeedback_text\n",
      "4\t4\tPizza was average.\n",
      "5\t5\tPizza was average.\n",
      "6\t6\tPizza was average.\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE orders (\n",
      "\torder_id SERIAL NOT NULL, \n",
      "\tcustomer_id INTEGER NOT NULL, \n",
      "\tpreparation_time INTEGER NOT NULL, \n",
      "\torder_date TIMESTAMP WITHOUT TIME ZONE DEFAULT CURRENT_TIMESTAMP, \n",
      "\tCONSTRAINT orders_pkey PRIMARY KEY (order_id), \n",
      "\tCONSTRAINT orders_customer_id_fkey FOREIGN KEY(customer_id) REFERENCES customer (customer_id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from orders table:\n",
      "order_id\tcustomer_id\tpreparation_time\torder_date\n",
      "1\t7\t11\t2024-06-15 07:22:59.427381\n",
      "2\t13\t13\t2024-06-15 07:22:59.427381\n",
      "3\t8\t20\t2024-06-15 07:22:59.427381\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE ordertoppings (\n",
      "\torder_id INTEGER NOT NULL, \n",
      "\ttopping_id INTEGER NOT NULL, \n",
      "\tCONSTRAINT ordertoppings_pkey PRIMARY KEY (order_id, topping_id), \n",
      "\tCONSTRAINT ordertoppings_order_id_fkey FOREIGN KEY(order_id) REFERENCES orders (order_id), \n",
      "\tCONSTRAINT ordertoppings_topping_id_fkey FOREIGN KEY(topping_id) REFERENCES toppings (topping_id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from ordertoppings table:\n",
      "order_id\ttopping_id\n",
      "1\t4\n",
      "1\t2\n",
      "1\t3\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE toppings (\n",
      "\ttopping_id SERIAL NOT NULL, \n",
      "\tname VARCHAR(50) NOT NULL, \n",
      "\tbase_preparation_time INTEGER NOT NULL, \n",
      "\tCONSTRAINT toppings_pkey PRIMARY KEY (topping_id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from toppings table:\n",
      "topping_id\tname\tbase_preparation_time\n",
      "1\tPepperoni\t5\n",
      "2\tMushrooms\t3\n",
      "3\tOnions\t2\n",
      "*/\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T07:18:56.389633Z",
     "start_time": "2024-07-26T07:18:54.657593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_agents._models import get_llm\n",
    "\n",
    "llm_llama3 = get_llm(llm_type='llama3', llm_model='llama3-70b-8192', api_key=groq_api_key)"
   ],
   "id": "6ab85ee34f83923b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T07:18:56.420284Z",
     "start_time": "2024-07-26T07:18:56.392628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langchain_core.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, ValidationError\n",
    "from typing import List, Optional\n",
    "\n",
    "REFLEXION_LOOP_COUNT = 3\n",
    "\n",
    "\n",
    "class Reflection(BaseModel):\n",
    "    \"\"\"Reflection on the generated SQL query.\"\"\"\n",
    "    good: str = Field(description=\"Critique of what is good in the given Postgres SQL query.\")\n",
    "    missing: str = Field(description=\"Critique of what is missing in the given Postgres SQL query.\")\n",
    "    improvements: Optional[str] = Field(description=\"Suggestions for improvements for the given Postgres SQL query.\")\n",
    "\n",
    "class AnswerQuestion(BaseModel):\n",
    "    \"\"\"Generate a SQL query to retrieve the data to answer the question. Provide a reflection on the generated query.\"\"\"\n",
    "\n",
    "    select_query: str = Field(...,\n",
    "                              description=\"A PostgreSQL SELECT statement to retrieve the data inorder to answer the question.\")\n",
    "    df_columns: List[str] = Field(\n",
    "        ..., description=\"Ordered names to give the DataFrame columns.\"\n",
    "    )\n",
    "    df_name: str = Field(\n",
    "        ..., description=\"The name to give the DataFrame variable in downstream code.\"\n",
    "    )\n",
    "    reflection: Reflection = Field(description=\"Your reflection on the generated select query.\")\n",
    "\n",
    "\n",
    "class ResponderWithRetries:\n",
    "    def __init__(self, runnable, validator):\n",
    "        self.runnable = runnable\n",
    "        self.validator = validator\n",
    "\n",
    "    def respond(self, state: list):\n",
    "        response = []\n",
    "        for attempt in range(REFLEXION_LOOP_COUNT):\n",
    "            print(f\"attempt: {attempt}\")\n",
    "            response = self.runnable.invoke(\n",
    "                {\"messages\": state}, {\"tags\": [f\"attempt:{attempt}\"]}\n",
    "            )\n",
    "            try:\n",
    "                self.validator.invoke(response)\n",
    "                return response\n",
    "            except ValidationError as e:\n",
    "                state = state + [\n",
    "                    response,\n",
    "                    ToolMessage(\n",
    "                        content=f\"{repr(e)}\\n\\nPay close attention to the function schema.\\n\\n\"\n",
    "                                + self.validator.schema_json()\n",
    "                                + \" Respond by fixing all validation errors.\",\n",
    "                        tool_call_id=response.tool_calls[0][\"id\"],\n",
    "                    ),\n",
    "                ]\n",
    "        return response"
   ],
   "id": "7538d9aeeeb5f77f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T07:18:57.042440Z",
     "start_time": "2024-07-26T07:18:56.422285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "\n",
    "retrieve_from_db_prompt_string = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            f\"\"\"\n",
    "You are an expert at PostgreSQL. You have access to a PostgreSQL database \n",
    "with the following tables\n",
    "\n",
    "{db.table_info}\n",
    "\n",
    "Given a user question related to the data in the database, \n",
    "1. {{first_instruction}}\n",
    "2. get the relevant data from the tables as a DataFrame using the {{function_name}} tool. \n",
    "3. Reflect and critique your answer based on the user question. Be severe to maximize improvement.\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"\\n\\n<system>Reflect on the user's original question and the\"\n",
    "            \" actions taken thus far. Respond using the {function_name} function.</reminder>\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(\n",
    "    time=lambda: datetime.datetime.now().isoformat(),\n",
    ")\n",
    "\n",
    "initial_answer_chain = retrieve_from_db_prompt_string.partial(\n",
    "    first_instruction=\"Generate a SQL query to retrieve the data to answer the question.\",\n",
    "    function_name=AnswerQuestion.__name__,\n",
    ") | llm_llama3.bind_tools(tools=[AnswerQuestion])\n",
    "validator = PydanticToolsParser(tools=[AnswerQuestion])\n",
    "\n",
    "first_responder = ResponderWithRetries(\n",
    "    runnable=initial_answer_chain, validator=validator\n",
    ")"
   ],
   "id": "9054e40f1b76aa58",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T07:18:58.475868Z",
     "start_time": "2024-07-26T07:18:57.045437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example_question = \"Graph the total number of orders of each customer. X axis of the graph has to be in ascending order.\"\n",
    "initial = first_responder.respond([HumanMessage(content=example_question)])\n",
    "initial"
   ],
   "id": "b4045877af0fcaeb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_1pwq', 'function': {'arguments': '{\"select_query\":\"SELECT customer_id, COUNT(order_id) as total_orders FROM orders GROUP BY customer_id ORDER BY customer_id ASC\",\"df_columns\":[\"customer_id\",\"total_orders\"],\"df_name\":\"customer_orders\",\"reflection\":{\"good\":\"The query effectively groups the orders by customer ID and counts the total orders for each customer.\",\"improvements\":\"Consider adding a filter to only include customers with a minimum number of orders.\",\"missing\":\"The query does not provide any additional insights beyond the total orders per customer.\"}}', 'name': 'AnswerQuestion'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 152, 'prompt_tokens': 1916, 'total_tokens': 2068, 'completion_time': 0.482247719, 'prompt_time': 0.163654674, 'queue_time': None, 'total_time': 0.6459023930000001}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3044b7d1-90db-44da-838f-1cbfc1d14b73-0', tool_calls=[{'name': 'AnswerQuestion', 'args': {'select_query': 'SELECT customer_id, COUNT(order_id) as total_orders FROM orders GROUP BY customer_id ORDER BY customer_id ASC', 'df_columns': ['customer_id', 'total_orders'], 'df_name': 'customer_orders', 'reflection': {'good': 'The query effectively groups the orders by customer ID and counts the total orders for each customer.', 'improvements': 'Consider adding a filter to only include customers with a minimum number of orders.', 'missing': 'The query does not provide any additional insights beyond the total orders per customer.'}}, 'id': 'call_1pwq'}])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1.2 Response after Reflexion",
   "id": "9e8a0c1936789ce7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T07:18:58.522036Z",
     "start_time": "2024-07-26T07:18:58.479866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "revise_instructions = f\"\"\"\n",
    "You are an expert at PostgreSQL. You have access to a PostgreSQL database \n",
    "with the following tables\n",
    "\n",
    "{db.table_info}\n",
    "\n",
    "Revise your previous_select_query using given reflection.\n",
    "You should use ReviseAnswer tool to give your answer.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ReviseAnswer(AnswerQuestion):\n",
    "    \"\"\"Revise your original PostgreSQL SELECT statement to your question. Provide an answer and \n",
    "    reflection on the revised answer.\"\"\"\n",
    "\n",
    "    new_query: str = Field(\n",
    "        description=\"The revised PostgreSQL SELECT statement according to given reflection.\"\n",
    "    )\n",
    "\n",
    "\n",
    "revision_chain = retrieve_from_db_prompt_string.partial(\n",
    "    first_instruction=revise_instructions,\n",
    "    function_name=ReviseAnswer.__name__,\n",
    ") | llm_llama3.bind_tools(tools=[ReviseAnswer])\n",
    "revision_validator = PydanticToolsParser(tools=[ReviseAnswer])\n",
    "\n",
    "revisor = ResponderWithRetries(runnable=revision_chain, validator=revision_validator)"
   ],
   "id": "9762bacc86771e6b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T07:18:59.642240Z",
     "start_time": "2024-07-26T07:18:58.524039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "revised = revisor.respond(\n",
    "    [\n",
    "        HumanMessage(content=example_question),\n",
    "        initial,\n",
    "        ToolMessage(\n",
    "            tool_call_id=initial.tool_calls[0][\"id\"],\n",
    "            content=json.dumps(\n",
    "                {\n",
    "                 \"reflection\": initial.tool_calls[0][\"args\"][\"reflection\"]\n",
    "                }\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "revised"
   ],
   "id": "b077460e81287dc3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempt: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_3rsc', 'function': {'arguments': '{\"select_query\":\"SELECT customer_id, COUNT(order_id) as total_orders FROM orders GROUP BY customer_id ORDER BY customer_id ASC\",\"df_columns\":[\"customer_id\",\"total_orders\"],\"df_name\":\"customer_orders\",\"new_query\":\"\",\"reflection\":{\"good\":\"The query effectively groups the orders by customer ID and counts the total orders for each customer.\",\"improvements\":\"Consider adding a filter to only include customers with a minimum number of orders.\",\"missing\":\"The query does not provide any additional insights beyond the total orders per customer.\"}}', 'name': 'ReviseAnswer'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 134, 'prompt_tokens': 2765, 'total_tokens': 2899, 'completion_time': 0.436089355, 'prompt_time': 0.257014212, 'queue_time': None, 'total_time': 0.6931035670000001}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_87cbfbbc4d', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-76ffd439-cb66-43dc-876d-42d882ef5962-0', tool_calls=[{'name': 'ReviseAnswer', 'args': {'select_query': 'SELECT customer_id, COUNT(order_id) as total_orders FROM orders GROUP BY customer_id ORDER BY customer_id ASC', 'df_columns': ['customer_id', 'total_orders'], 'df_name': 'customer_orders', 'new_query': '', 'reflection': {'good': 'The query effectively groups the orders by customer ID and counts the total orders for each customer.', 'improvements': 'Consider adding a filter to only include customers with a minimum number of orders.', 'missing': 'The query does not provide any additional insights beyond the total orders per customer.'}}, 'id': 'call_3rsc'}])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.3 Create Tool Node",
   "id": "6d21aff56ddac9ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T07:20:48.596381Z",
     "start_time": "2024-07-26T07:20:48.572973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "def run_queries(reflection: dict, **kwargs):\n",
    "    \"\"\"Run the generated queries.\"\"\"\n",
    "    recommendation = reflection['missing'] + reflection['improvements']\n",
    "    return [{\"reflection\": recommendation}]\n",
    "\n",
    "\n",
    "tool_node = ToolNode(\n",
    "    [\n",
    "        StructuredTool.from_function(run_queries, name=AnswerQuestion.__name__),\n",
    "        StructuredTool.from_function(run_queries, name=ReviseAnswer.__name__),\n",
    "    ]\n",
    ")"
   ],
   "id": "dc21da051ace811",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.4 Construct Graph",
   "id": "494dc29ac2d7d439"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T07:20:50.441275Z",
     "start_time": "2024-07-26T07:20:50.420269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO: Convert this into a StateGraph (now its a MessageGraph)\n",
    "\n",
    "from typing import Literal\n",
    "from langgraph.graph import END, MessageGraph, START\n",
    "\n",
    "MAX_ITERATIONS = 3\n",
    "builder = MessageGraph()\n",
    "builder.add_node(\"draft\", first_responder.respond)\n",
    "\n",
    "\n",
    "builder.add_node(\"execute_tools\", tool_node)\n",
    "builder.add_node(\"revise\", revisor.respond)\n",
    "# draft -> execute_tools\n",
    "builder.add_edge(\"draft\", \"execute_tools\")\n",
    "# execute_tools -> revise\n",
    "builder.add_edge(\"execute_tools\", \"revise\")\n",
    "\n",
    "# Define looping logic:\n",
    "\n",
    "\n",
    "def _get_num_iterations(state: list):\n",
    "    i = 0\n",
    "    for m in state[::-1]:\n",
    "        if m.type not in {\"tool\", \"ai\"}:\n",
    "            break\n",
    "        i += 1\n",
    "    return i\n",
    "\n",
    "\n",
    "def event_loop(state: list) -> Literal[\"execute_tools\", \"__end__\"]:\n",
    "    # in our case, we'll just stop after N plans\n",
    "    num_iterations = _get_num_iterations(state)\n",
    "    if num_iterations > MAX_ITERATIONS:\n",
    "        return END\n",
    "    return \"execute_tools\"\n",
    "\n",
    "\n",
    "# revise -> execute_tools OR end\n",
    "builder.add_conditional_edges(\"revise\", event_loop)\n",
    "builder.add_edge(START, \"draft\")\n",
    "graph = builder.compile()"
   ],
   "id": "622092815e173888",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T07:20:52.141584Z",
     "start_time": "2024-07-26T07:20:51.148825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "id": "856bb076bb08b561",
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T07:20:57.502439Z",
     "start_time": "2024-07-26T07:20:52.739803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "events = graph.stream(\n",
    "    [HumanMessage(content=example_question)],\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for i, step in enumerate(events):\n",
    "    print(f\"Step {i}\")\n",
    "    step[-1].pretty_print()"
   ],
   "id": "a3048f6024cabe0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Graph the total number of orders of each customer. X axis of the graph has to be in ascending order.\n",
      "attempt: 0\n",
      "Step 1\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  AnswerQuestion (call_179c)\n",
      " Call ID: call_179c\n",
      "  Args:\n",
      "    select_query: SELECT customer_id, COUNT(order_id) as total_orders FROM orders GROUP BY customer_id ORDER BY customer_id ASC\n",
      "    df_columns: ['customer_id', 'total_orders']\n",
      "    df_name: customer_orders\n",
      "    reflection: {'good': 'The query effectively groups the orders by customer ID and counts the total orders for each customer.', 'improvements': 'Consider adding a filter to only include customers with a minimum number of orders.', 'missing': 'The query does not provide any additional insights beyond the total orders per customer.'}\n",
      "Step 2\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: AnswerQuestion\n",
      "\n",
      "[{\"reflection\": \"The query does not provide any additional insights beyond the total orders per customer.Consider adding a filter to only include customers with a minimum number of orders.\"}]\n",
      "attempt: 0\n",
      "Step 3\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  ReviseAnswer (call_vxna)\n",
      " Call ID: call_vxna\n",
      "  Args:\n",
      "    select_query: SELECT customer_id, COUNT(order_id) as total_orders FROM orders GROUP BY customer_id ORDER BY customer_id ASC\n",
      "    df_columns: ['customer_id', 'total_orders']\n",
      "    df_name: customer_orders\n",
      "    new_query: \n",
      "    reflection: {'good': 'The query effectively groups the orders by customer ID and counts the total orders for each customer.', 'improvements': 'Consider adding a filter to only include customers with a minimum number of orders.', 'missing': 'The query does not provide any additional insights beyond the total orders per customer.'}\n",
      "Step 4\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: ReviseAnswer\n",
      "\n",
      "[{\"reflection\": \"The query does not provide any additional insights beyond the total orders per customer.Consider adding a filter to only include customers with a minimum number of orders.\"}]\n",
      "attempt: 0\n",
      "Step 5\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  ReviseAnswer (call_088p)\n",
      " Call ID: call_088p\n",
      "  Args:\n",
      "    select_query: SELECT customer_id, COUNT(order_id) as total_orders FROM orders GROUP BY customer_id ORDER BY customer_id ASC\n",
      "    df_columns: ['customer_id', 'total_orders']\n",
      "    df_name: customer_orders\n",
      "    new_query: \n",
      "    reflection: {'good': 'The query effectively groups the orders by customer ID and counts the total orders for each customer.', 'improvements': 'Consider adding a filter to only include customers with a minimum number of orders.', 'missing': 'The query does not provide any additional insights beyond the total orders per customer.'}\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fbac606ddcc5d3a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
